{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import os, sys\n",
    "current_dir = os.getcwd()\n",
    "# Append the parent directory to sys.path\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "sys.path.append(parent_dir)\n",
    "\n",
    "# ignore warrning message\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.model_development_scripts import ModelPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fraud_data = pd.read_csv('../data/proccessed_fraud_data.csv')\n",
    "credit_data = pd.read_csv('../data/creditcard.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>signup_time</th>\n",
       "      <th>purchase_time</th>\n",
       "      <th>purchase_value</th>\n",
       "      <th>device_id</th>\n",
       "      <th>age</th>\n",
       "      <th>class</th>\n",
       "      <th>ip_int</th>\n",
       "      <th>country</th>\n",
       "      <th>hour_of_day</th>\n",
       "      <th>...</th>\n",
       "      <th>time_diff</th>\n",
       "      <th>transaction_frequency</th>\n",
       "      <th>average_velocity</th>\n",
       "      <th>source_Direct</th>\n",
       "      <th>source_SEO</th>\n",
       "      <th>browser_FireFox</th>\n",
       "      <th>browser_IE</th>\n",
       "      <th>browser_Opera</th>\n",
       "      <th>browser_Safari</th>\n",
       "      <th>sex_M</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2015-01-11 03:47:13</td>\n",
       "      <td>2015-02-21 10:03:37</td>\n",
       "      <td>0.310345</td>\n",
       "      <td>FGBQNDNBETFJJ</td>\n",
       "      <td>0.120690</td>\n",
       "      <td>0</td>\n",
       "      <td>880217484</td>\n",
       "      <td>United States</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>2015-06-02 16:40:57</td>\n",
       "      <td>2015-09-26 21:32:16</td>\n",
       "      <td>0.220690</td>\n",
       "      <td>MKFUIVOHLJBYN</td>\n",
       "      <td>0.344828</td>\n",
       "      <td>0</td>\n",
       "      <td>2785906106</td>\n",
       "      <td>Switzerland</td>\n",
       "      <td>21</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>2015-05-28 07:53:06</td>\n",
       "      <td>2015-08-13 11:53:07</td>\n",
       "      <td>0.262069</td>\n",
       "      <td>SCQGQALXBUQZJ</td>\n",
       "      <td>0.120690</td>\n",
       "      <td>0</td>\n",
       "      <td>356056736</td>\n",
       "      <td>United States</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12</td>\n",
       "      <td>2015-01-10 06:25:12</td>\n",
       "      <td>2015-03-04 20:56:37</td>\n",
       "      <td>0.179310</td>\n",
       "      <td>MSNWCFEHKTIOY</td>\n",
       "      <td>0.017241</td>\n",
       "      <td>0</td>\n",
       "      <td>2985180352</td>\n",
       "      <td>Mexico</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16</td>\n",
       "      <td>2015-02-03 13:48:23</td>\n",
       "      <td>2015-03-12 12:46:23</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>FROZWSSWOHZBE</td>\n",
       "      <td>0.241379</td>\n",
       "      <td>0</td>\n",
       "      <td>578312545</td>\n",
       "      <td>United States</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id          signup_time        purchase_time  purchase_value  \\\n",
       "0        2  2015-01-11 03:47:13  2015-02-21 10:03:37        0.310345   \n",
       "1        4  2015-06-02 16:40:57  2015-09-26 21:32:16        0.220690   \n",
       "2        8  2015-05-28 07:53:06  2015-08-13 11:53:07        0.262069   \n",
       "3       12  2015-01-10 06:25:12  2015-03-04 20:56:37        0.179310   \n",
       "4       16  2015-02-03 13:48:23  2015-03-12 12:46:23        0.000000   \n",
       "\n",
       "       device_id       age  class      ip_int        country  hour_of_day  \\\n",
       "0  FGBQNDNBETFJJ  0.120690      0   880217484  United States           10   \n",
       "1  MKFUIVOHLJBYN  0.344828      0  2785906106    Switzerland           21   \n",
       "2  SCQGQALXBUQZJ  0.120690      0   356056736  United States           11   \n",
       "3  MSNWCFEHKTIOY  0.017241      0  2985180352         Mexico           20   \n",
       "4  FROZWSSWOHZBE  0.241379      0   578312545  United States           12   \n",
       "\n",
       "   ...  time_diff  transaction_frequency  average_velocity  source_Direct  \\\n",
       "0  ...        0.0                      1               0.0              0   \n",
       "1  ...        0.0                      1               0.0              1   \n",
       "2  ...        0.0                      1               0.0              0   \n",
       "3  ...        0.0                      1               0.0              0   \n",
       "4  ...        0.0                      1               0.0              1   \n",
       "\n",
       "   source_SEO  browser_FireFox  browser_IE  browser_Opera  browser_Safari  \\\n",
       "0           1                0           0              0               0   \n",
       "1           0                0           0              0               1   \n",
       "2           1                0           0              0               0   \n",
       "3           0                0           0              0               1   \n",
       "4           0                0           1              0               0   \n",
       "\n",
       "   sex_M  \n",
       "0      0  \n",
       "1      0  \n",
       "2      1  \n",
       "3      1  \n",
       "4      1  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fraud_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1], dtype=int64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fraud_data.transaction_frequency.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unnecessary columns\n",
    "fraud_data = fraud_data.drop(['user_id', 'device_id', 'transaction_frequency','time_diff','average_velocity', 'ip_int', 'signup_time', 'purchase_time'], axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Frequency Encoding\n",
    "In this method, I replace each category with its frequency in the fraud dataset. This can help maintain some information about the category without expanding the feature space too much."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frequency Encoding Example\n",
    "frequency = fraud_data['country'].value_counts()\n",
    "fraud_data['country_encoded'] = fraud_data['country'].map(frequency)\n",
    "\n",
    "# Drop the original 'country' column\n",
    "fraud_data = fraud_data.drop('country', axis=1)\n",
    "\n",
    "# scale 'country_encoded' column\n",
    "scaler = MinMaxScaler()\n",
    "fraud_data['country_encoded'] = scaler.fit_transform(fraud_data[['country_encoded']])[:, 0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "fraud_data.to_csv('../data/final_preprocessed_fraud_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>purchase_value</th>\n",
       "      <th>age</th>\n",
       "      <th>class</th>\n",
       "      <th>hour_of_day</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>source_Direct</th>\n",
       "      <th>source_SEO</th>\n",
       "      <th>browser_FireFox</th>\n",
       "      <th>browser_IE</th>\n",
       "      <th>browser_Opera</th>\n",
       "      <th>browser_Safari</th>\n",
       "      <th>sex_M</th>\n",
       "      <th>country_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.310345</td>\n",
       "      <td>0.120690</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.220690</td>\n",
       "      <td>0.344828</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.013506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.262069</td>\n",
       "      <td>0.120690</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.179310</td>\n",
       "      <td>0.017241</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.019294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.241379</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129141</th>\n",
       "      <td>0.503448</td>\n",
       "      <td>0.706897</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.054438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129142</th>\n",
       "      <td>0.075862</td>\n",
       "      <td>0.327586</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.062793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129143</th>\n",
       "      <td>0.165517</td>\n",
       "      <td>0.293103</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.125844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129144</th>\n",
       "      <td>0.393103</td>\n",
       "      <td>0.517241</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129145</th>\n",
       "      <td>0.337931</td>\n",
       "      <td>0.120690</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>129146 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        purchase_value       age  class  hour_of_day  day_of_week  \\\n",
       "0             0.310345  0.120690      0           10            5   \n",
       "1             0.220690  0.344828      0           21            5   \n",
       "2             0.262069  0.120690      0           11            3   \n",
       "3             0.179310  0.017241      0           20            2   \n",
       "4             0.000000  0.241379      0           12            3   \n",
       "...                ...       ...    ...          ...          ...   \n",
       "129141        0.503448  0.706897      0            7            2   \n",
       "129142        0.075862  0.327586      0            7            3   \n",
       "129143        0.165517  0.293103      0           23            4   \n",
       "129144        0.393103  0.517241      0           20            2   \n",
       "129145        0.337931  0.120690      1            6            0   \n",
       "\n",
       "        source_Direct  source_SEO  browser_FireFox  browser_IE  browser_Opera  \\\n",
       "0                   0           1                0           0              0   \n",
       "1                   1           0                0           0              0   \n",
       "2                   0           1                0           0              0   \n",
       "3                   0           0                0           0              0   \n",
       "4                   1           0                0           1              0   \n",
       "...               ...         ...              ...         ...            ...   \n",
       "129141              1           0                0           0              0   \n",
       "129142              1           0                0           1              0   \n",
       "129143              1           0                1           0              0   \n",
       "129144              1           0                0           0              0   \n",
       "129145              0           0                0           0              0   \n",
       "\n",
       "        browser_Safari  sex_M  country_encoded  \n",
       "0                    0      0         1.000000  \n",
       "1                    1      0         0.013506  \n",
       "2                    0      1         1.000000  \n",
       "3                    1      1         0.019294  \n",
       "4                    0      1         1.000000  \n",
       "...                ...    ...              ...  \n",
       "129141               1      1         0.054438  \n",
       "129142               0      0         0.062793  \n",
       "129143               0      0         0.125844  \n",
       "129144               0      1         1.000000  \n",
       "129145               0      1         1.000000  \n",
       "\n",
       "[129146 rows x 13 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fraud_data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Development for Fraud_detaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage for fraud dataset:\n",
    "fraud_data_file_path = '../data/final_preprocessed_fraud_data.csv'\n",
    "fraud_pipeline = ModelPipeline('fraud', fraud_data_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-21 23:15:16,327 - INFO - Loading fraud data from ../data/final_preprocessed_fraud_data.csv...\n",
      "2024-10-21 23:15:16,636 - INFO - Data loading complete.\n"
     ]
    }
   ],
   "source": [
    "fraud_pipeline.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-21 23:15:18,063 - INFO - Data has been split into train and test sets.\n"
     ]
    }
   ],
   "source": [
    "fraud_pipeline.split_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-21 23:15:19,578 - INFO - Applying SMOTE to the training data...\n",
      "2024-10-21 23:15:20,218 - INFO - SMOTE applied to training data. Classes have been balanced.\n"
     ]
    }
   ],
   "source": [
    "fraud_pipeline.apply_smote()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "models = [\n",
    "            (LogisticRegression(), 'Logistic Regression'),\n",
    "            (DecisionTreeClassifier(), 'Decision Tree'),\n",
    "            (RandomForestClassifier(), 'Random Forest'),\n",
    "            (GradientBoostingClassifier(), 'Gradient Boosting')\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-21 23:15:39,348 - INFO - Training Logistic Regression on fraud dataset...\n",
      "2024-10-21 23:15:41,088 - INFO - Logistic Regression training complete.\n",
      "2024-10-21 23:15:41,094 - INFO - Evaluating Logistic Regression on fraud dataset...\n",
      "2024-10-21 23:15:41,319 - INFO - Logistic Regression evaluation report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.59      0.72     23389\n",
      "           1       0.10      0.42      0.16      2441\n",
      "\n",
      "    accuracy                           0.58     25830\n",
      "   macro avg       0.50      0.51      0.44     25830\n",
      "weighted avg       0.83      0.58      0.67     25830\n",
      "\n",
      "2024-10-21 23:15:41,320 - INFO - Logging Logistic Regression to MLflow...\n",
      "2024/10/21 23:16:05 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2024-10-21 23:16:05,853 - INFO - Logistic Regression has been logged and saved in MLflow as version 1.\n",
      "2024-10-21 23:16:05,870 - INFO - Training Decision Tree on fraud dataset...\n",
      "2024-10-21 23:16:09,151 - INFO - Decision Tree training complete.\n",
      "2024-10-21 23:16:09,153 - INFO - Evaluating Decision Tree on fraud dataset...\n",
      "2024-10-21 23:16:09,328 - INFO - Decision Tree evaluation report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.92      0.94     23389\n",
      "           1       0.43      0.59      0.50      2441\n",
      "\n",
      "    accuracy                           0.89     25830\n",
      "   macro avg       0.69      0.75      0.72     25830\n",
      "weighted avg       0.91      0.89      0.90     25830\n",
      "\n",
      "2024-10-21 23:16:09,328 - INFO - Logging Decision Tree to MLflow...\n",
      "2024/10/21 23:16:24 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2024-10-21 23:16:24,325 - INFO - Decision Tree has been logged and saved in MLflow as version 1.\n",
      "2024-10-21 23:16:24,338 - INFO - Training Random Forest on fraud dataset...\n",
      "2024-10-21 23:17:18,900 - INFO - Random Forest training complete.\n",
      "2024-10-21 23:17:18,902 - INFO - Evaluating Random Forest on fraud dataset...\n",
      "2024-10-21 23:17:20,384 - INFO - Random Forest evaluation report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.98      0.97     23389\n",
      "           1       0.75      0.55      0.64      2441\n",
      "\n",
      "    accuracy                           0.94     25830\n",
      "   macro avg       0.85      0.77      0.80     25830\n",
      "weighted avg       0.94      0.94      0.94     25830\n",
      "\n",
      "2024-10-21 23:17:20,387 - INFO - Logging Random Forest to MLflow...\n",
      "2024/10/21 23:18:16 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2024-10-21 23:18:53,451 - INFO - Random Forest has been logged and saved in MLflow as version 1.\n",
      "2024-10-21 23:18:53,466 - INFO - Training Gradient Boosting on fraud dataset...\n",
      "2024-10-21 23:19:37,352 - INFO - Gradient Boosting training complete.\n",
      "2024-10-21 23:19:37,354 - INFO - Evaluating Gradient Boosting on fraud dataset...\n",
      "2024-10-21 23:19:37,622 - INFO - Gradient Boosting evaluation report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.80      0.86     23389\n",
      "           1       0.14      0.30      0.19      2441\n",
      "\n",
      "    accuracy                           0.76     25830\n",
      "   macro avg       0.53      0.55      0.52     25830\n",
      "weighted avg       0.84      0.76      0.79     25830\n",
      "\n",
      "2024-10-21 23:19:37,624 - INFO - Logging Gradient Boosting to MLflow...\n",
      "2024/10/21 23:20:00 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2024-10-21 23:20:00,331 - INFO - Gradient Boosting has been logged and saved in MLflow as version 1.\n"
     ]
    }
   ],
   "source": [
    "for model, name in models:\n",
    "            fraud_pipeline.train_model(model, name)\n",
    "            report = fraud_pipeline.evaluate_model(model, name)\n",
    "            fraud_pipeline.log_model(model, name, report)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model development for Credit Card"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/10/20 21:28:10 INFO mlflow.tracking.fluent: Experiment with name 'creditcard_experiment' does not exist. Creating a new experiment.\n"
     ]
    }
   ],
   "source": [
    "#  model development for credit card\n",
    "creditcard_file_path = '../data/creditcard.csv'\n",
    "creditcard_pipeline = ModelPipeline('creditcard', creditcard_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-20 21:28:11,996 - INFO - Loading credit card data from ../data/creditcard.csv...\n",
      "2024-10-20 21:28:16,771 - INFO - Data loading complete.\n"
     ]
    }
   ],
   "source": [
    "creditcard_pipeline.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-20 21:28:19,711 - INFO - Data has been split into train and test sets.\n"
     ]
    }
   ],
   "source": [
    "creditcard_pipeline.split_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "credit_models = [\n",
    "            (LogisticRegression(), 'Logistic Regression'),\n",
    "            (DecisionTreeClassifier(), 'Decision Tree'),\n",
    "            (RandomForestClassifier(), 'Random Forest'),\n",
    "            (GradientBoostingClassifier(), 'Gradient Boosting')\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-20 21:28:41,492 - INFO - Training Logistic Regression on creditcard dataset...\n",
      "2024-10-20 21:28:48,281 - INFO - Logistic Regression training complete.\n",
      "2024-10-20 21:28:48,283 - INFO - Evaluating Logistic Regression on creditcard dataset...\n",
      "2024-10-20 21:28:48,575 - INFO - Logistic Regression evaluation report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56864\n",
      "           1       0.61      0.56      0.59        98\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.81      0.78      0.79     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n",
      "2024-10-20 21:28:48,577 - INFO - Logging Logistic Regression to MLflow...\n",
      "2024/10/20 21:29:01 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2024-10-20 21:29:02,080 - INFO - Logistic Regression has been logged and saved in MLflow.\n",
      "2024-10-20 21:29:02,092 - INFO - Training Decision Tree on creditcard dataset...\n",
      "2024-10-20 21:29:45,552 - INFO - Decision Tree training complete.\n",
      "2024-10-20 21:29:45,555 - INFO - Evaluating Decision Tree on creditcard dataset...\n",
      "2024-10-20 21:29:46,068 - INFO - Decision Tree evaluation report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56864\n",
      "           1       0.70      0.76      0.73        98\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.85      0.88      0.86     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n",
      "2024-10-20 21:29:46,073 - INFO - Logging Decision Tree to MLflow...\n",
      "2024/10/20 21:30:05 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2024-10-20 21:30:05,401 - INFO - Decision Tree has been logged and saved in MLflow.\n",
      "2024-10-20 21:30:05,415 - INFO - Training Random Forest on creditcard dataset...\n",
      "2024-10-20 21:37:34,940 - INFO - Random Forest training complete.\n",
      "2024-10-20 21:37:34,942 - INFO - Evaluating Random Forest on creditcard dataset...\n",
      "2024-10-20 21:37:36,171 - INFO - Random Forest evaluation report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56864\n",
      "           1       0.96      0.79      0.87        98\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.98      0.89      0.93     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n",
      "2024-10-20 21:37:36,174 - INFO - Logging Random Forest to MLflow...\n",
      "2024/10/20 21:37:51 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2024-10-20 21:37:51,700 - INFO - Random Forest has been logged and saved in MLflow.\n",
      "2024-10-20 21:37:51,725 - INFO - Training Gradient Boosting on creditcard dataset...\n",
      "2024-10-20 21:49:41,629 - INFO - Gradient Boosting training complete.\n",
      "2024-10-20 21:49:41,633 - INFO - Evaluating Gradient Boosting on creditcard dataset...\n",
      "2024-10-20 21:49:41,940 - INFO - Gradient Boosting evaluation report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56864\n",
      "           1       0.74      0.60      0.66        98\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.87      0.80      0.83     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n",
      "2024-10-20 21:49:41,942 - INFO - Logging Gradient Boosting to MLflow...\n",
      "2024/10/20 21:49:56 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2024-10-20 21:49:56,632 - INFO - Gradient Boosting has been logged and saved in MLflow.\n"
     ]
    }
   ],
   "source": [
    "for model, name in credit_models:\n",
    "            creditcard_pipeline.train_model(model, name)\n",
    "            report = creditcard_pipeline.evaluate_model(model, name)\n",
    "            creditcard_pipeline.log_model(model, name, report)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optionaly we can use ModelPipline to run the model once\n",
    "- **For Credit card fraud detaction**: \n",
    "\n",
    "```python\n",
    "pipeline = ModelPipeline(dataset_type='creditcard', path='path/to/creditcard_data.csv')\n",
    "pipeline.run_pipeline()\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **For Bank transaction Fraud detaction**:\n",
    "\n",
    "```python\n",
    "pipeline = ModelPipeline(dataset_type='fraud', path='path/to/fraud_data.csv')\n",
    "pipeline.run_pipeline()\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
